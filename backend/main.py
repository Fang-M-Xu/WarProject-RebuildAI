import os
from typing import List, Dict, Any
import uuid
from dotenv import load_dotenv
from openai import OpenAI
import pandas as pd
from IPython.display import Markdown, display
from db.VectorDBManager import VectorDBManager  
from db.UploaderData import UploaderData


# Load environment variables
load_dotenv()

class WarUseCaseAnalyzer:
    """
    A class that analyzes war-related use cases, their risks, benefits, and mitigations
    using RAG (Retrieval Augmented Generation) with Pinecone and an LLM.
    """
    
    def __init__(self):
        """Initialize the analyzer with necessary components."""
        # Load API keys from environment variables
        pinecone_api = os.getenv("PINECONE_API_KEY")
        openai_api = os.getenv("OPENAI_API_KEY")
        
        if not pinecone_api or not openai_api:
            raise ValueError("Missing required API keys in environment variables")
        
        self.index_name = os.getenv("PINECONE_INDEX_NAME", "war-use-cases")
        self.llm_model = os.getenv("LLM_MODEL", "gpt-4o-mini")
        
        # Initialize OpenAI client
        self.client = OpenAI(api_key=openai_api)
        
        # Initialize vector DB managers for different collections
        self.use_cases_db = VectorDBManager(
            pinecone_api=pinecone_api,
            openai_api=openai_api,
            index_name=self.index_name,
            namespace="use_cases"
        )
        
        # Separate namespaces for risks and benefits
        self.risks_db = VectorDBManager(
            pinecone_api=pinecone_api,
            openai_api=openai_api,
            index_name=self.index_name,
            namespace="risks"
        )
        
        self.benefits_db = VectorDBManager(
            pinecone_api=pinecone_api,
            openai_api=openai_api,
            index_name=self.index_name,
            namespace="benefits"
        )
        
        self.mitigations_db = VectorDBManager(
            pinecone_api=pinecone_api,
            openai_api=openai_api,
            index_name=self.index_name,
            namespace="mitigations"
        )
    
    def _query_llm(self, prompt: str, messages: List[Dict[str, str]] = None, temperature: float = 0.7):
        """
        Query the LLM with a given prompt.
        
        Args:
            prompt: The prompt to send to the LLM
            messages: Optional message history
            temperature: Control randomness (0.0 = deterministic, 1.0 = creative)
            
        Returns:
            The LLM's response text
        """
        if messages is None:
            messages = [{"role": "user", "content": prompt}]
        else:
            messages.append({"role": "user", "content": prompt})
        
        completion = self.client.chat.completions.create(
            model=self.llm_model,
            messages=messages,
            temperature=temperature
        )
        
        return completion.choices[0].message.content
    
    def find_use_cases(self, query: str, top_k: int = 3):
        """
        Find relevant use cases based on the user query.
        
        Args:
            query: User's query about a war-related AI use case
            top_k: Number of use cases to retrieve
            
        Returns:
            Dictionary of use cases with their details
        """
        print(f"Finding use cases for: '{query}'")
        results = self.use_cases_db.search_kb(query, top_k=top_k)
        
        use_cases = {}
        for match in results.matches:
            use_case_id = match.metadata.get("id", str(uuid.uuid4()))
            use_cases[use_case_id] = {
                "title": match.metadata.get("title", "Unnamed Use Case"),
                "description": match.metadata.get("description", "No description available"),
                "context": match.metadata.get("context", "No context available"),
                "score": match.score
            }
        
        # If no use cases found, provide a message
        if not use_cases:
            print("No relevant use cases found. Generating a generic response with the LLM.")
            llm_prompt = f"""
            No specific use cases were found in our database for the query: "{query}".
            Please generate a thoughtful analysis of potential AI applications in this context,
            focusing on how AI might be used in war or post-war scenarios related to this query.
            Format as a list of 2-3 potential use cases with titles and descriptions.
            """
            llm_response = self._query_llm(llm_prompt)
            
            # Creating a generic use case from LLM response
            use_cases["generic_response"] = {
                "title": f"AI Applications for: {query}",
                "description": llm_response,
                "context": "Generated by AI due to lack of specific database entries",
                "score": 1.0  # Default score
            }
        
        return use_cases
    
    def analyze_use_cases(self, query: str, use_cases: Dict[str, Dict[str, Any]]):
        """
        Analyze the retrieved use cases using the LLM.
        
        Args:
            query: Original user query
            use_cases: Dictionary of use cases to analyze
            
        Returns:
            Analysis of the use cases
        """
        use_cases_text = "\n\n".join([
            f"Use Case {idx+1}: {uc['title']}\n{uc['description']}\nContext: {uc['context']}"
            for idx, uc in enumerate(use_cases.values())
        ])
        
        prompt = f"""
        The user is interested in: "{query}"
        
        I've retrieved the following relevant use cases:
        
        {use_cases_text}
        
        Please analyze these use cases in relation to the user's query. Provide:
        1. A brief summary of how these use cases relate to the user's query
        2. Key insights from these use cases
        3. Potential applications or implementations
        
        Format your response as a structured analysis that helps the user understand the relevance and implications.
        """
        
        return self._query_llm(prompt)
    
    def find_risks_benefits(self, use_case: Dict[str, Any], top_k: int = 3):
        """
        Find risks and benefits for a specific use case using separate databases.
        
        Args:
            use_case: The use case to analyze
            top_k: Number of risks/benefits entries to retrieve
            
        Returns:
            Dictionary containing risks and benefits
        """
        risks_benefits = {
            "risks": [],
            "benefits": []
        }
        
        # Query for risks
        risks_query = f"risks of {use_case['title']} in war or post-war context"
        risks_results = self.risks_db.search_kb(risks_query, top_k=top_k)
        
        for match in risks_results.matches:
            if "risks" in match.metadata:
                risks_benefits["risks"].extend(match.metadata["risks"].split(";"))
        
        # Query for benefits
        benefits_query = f"benefits of {use_case['title']} in war or post-war context"
        benefits_results = self.benefits_db.search_kb(benefits_query, top_k=top_k)
        
        for match in benefits_results.matches:
            if "benefits" in match.metadata:
                risks_benefits["benefits"].extend(match.metadata["benefits"].split(";"))
        
        # Remove duplicates and empty entries
        risks_benefits["risks"] = list(set(filter(None, risks_benefits["risks"])))
        risks_benefits["benefits"] = list(set(filter(None, risks_benefits["benefits"])))
        
        # If no risks or benefits found, generate with LLM
        if not risks_benefits["risks"] or not risks_benefits["benefits"]:
            print(f"Generating risks and benefits for '{use_case['title']}' with LLM.")
            llm_prompt = f"""
            For the following AI use case in a war or post-war context:
            
            Title: {use_case['title']}
            Description: {use_case['description']}
            
            Please identify:
            1. The top potential risks of this application (ethical, social, technical, security)
            2. The top potential benefits of this application (humanitarian, social, technical, security)
            
            Format your response with clearly separated 'RISKS:' and 'BENEFITS:' sections.
            """
            llm_response = self._query_llm(llm_prompt)
            
            # Simple parsing of LLM response
            if "RISKS:" in llm_response and "BENEFITS:" in llm_response:
                parts = llm_response.split("BENEFITS:")
                risks_part = parts[0].replace("RISKS:", "").strip()
                benefits_part = parts[1].strip()
                
                # Fill in any missing risks or benefits
                if not risks_benefits["risks"]:
                    risks_benefits["risks"] = [r.strip() for r in risks_part.split("\n-") if r.strip()]
                
                if not risks_benefits["benefits"]:
                    risks_benefits["benefits"] = [b.strip() for b in benefits_part.split("\n-") if b.strip()]
            else:
                # Fallback if format wasn't followed
                if not risks_benefits["risks"]:
                    risks_benefits["risks"] = ["Risk assessment required"]
                
                if not risks_benefits["benefits"]:
                    risks_benefits["benefits"] = ["Benefit assessment required"]
        
        return risks_benefits
    
    def find_mitigations(self, risk: str, top_k: int = 2):
        """
        Find mitigations for a specific risk.
        
        Args:
            risk: The risk to find mitigations for
            top_k: Number of mitigation entries to retrieve
            
        Returns:
            List of mitigations
        """
        search_query = f"mitigations for {risk} in war or post-war context"
        results = self.mitigations_db.search_kb(search_query, top_k=top_k)
        
        mitigations = []
        for match in results.matches:
            if "mitigations" in match.metadata:
                mitigations.extend(match.metadata["mitigations"].split(";"))
        
        # Remove duplicates and empty entries
        mitigations = list(set(filter(None, mitigations)))
        
        # If no mitigations found, generate with LLM
        if not mitigations:
            print(f"Generating mitigations for risk '{risk}' with LLM.")
            llm_prompt = f"""
            For the following risk in using AI in a war or post-war context:
            
            Risk: {risk}
            
            Please provide 2-3 specific mitigation strategies that could help address this risk.
            Focus on practical, ethical, and implementable solutions.
            """
            llm_response = self._query_llm(llm_prompt)
            
            # Simple parsing: assume each line is a mitigation
            mitigations = [m.strip() for m in llm_response.split("\n") if m.strip()]
            
            # Filter out lines that are likely not mitigations
            mitigations = [m for m in mitigations if len(m) > 20 and not m.startswith("Mitigation")]
            
            # If still empty, use a fallback
            if not mitigations:
                mitigations = ["Mitigation assessment required"]
        
        return mitigations
    
    def generate_report(self, query: str, use_cases: Dict[str, Dict], use_cases_analysis: str, 
                        all_risks_benefits: Dict[str, Dict], all_mitigations: Dict[str, List[str]]):
        """
        Generate a comprehensive report based on all the collected information.
        
        Args:
            query: Original user query
            use_cases: Dictionary of use cases
            use_cases_analysis: Analysis of the use cases
            all_risks_benefits: Risks and benefits for each use case
            all_mitigations: Mitigations for each risk
            
        Returns:
            A formatted report
        """
        # Prepare the report content
        report_sections = []
        
        # Introduction section
        report_sections.append(f"""
        # AI War Use Case Analysis: {query}
        
        ## Executive Summary
        
        This report provides an analysis of AI applications related to "{query}" in war or post-war contexts.
        It examines relevant use cases, their risks and benefits, and potential mitigation strategies.
        
        ## Overview
        
        {use_cases_analysis}
        """)
        
        # Use cases section
        report_sections.append("## Detailed Analysis of Use Cases\n")
        
        for uc_id, use_case in use_cases.items():
            report_sections.append(f"""
            ### {use_case['title']}
            
            **Description:** {use_case['description']}
            
            **Context:** {use_case['context']}
            
            #### Benefits:
            """)
            
            # Add benefits
            benefits = all_risks_benefits.get(uc_id, {}).get("benefits", [])
            if benefits:
                for benefit in benefits:
                    report_sections.append(f"- {benefit}")
            else:
                report_sections.append("- No specific benefits identified")
            
            report_sections.append("\n#### Risks:")
            
            # Add risks and their mitigations
            risks = all_risks_benefits.get(uc_id, {}).get("risks", [])
            if risks:
                for risk_idx, risk in enumerate(risks):
                    report_sections.append(f"- **{risk}**")
                    
                    # Add mitigations for this risk
                    mitigations = all_mitigations.get(f"{uc_id}_{risk_idx}", [])
                    if mitigations:
                        report_sections.append("  *Potential mitigations:*")
                        for mitigation in mitigations:
                            report_sections.append(f"  - {mitigation}")
                    else:
                        report_sections.append("  *Mitigations not identified*")
            else:
                report_sections.append("- No specific risks identified")
        
        # Conclusion section
        report_sections.append("""
        ## Conclusion
        
        This analysis provides a framework for understanding how AI can be applied in this context, 
        what risks should be considered, and how these risks might be mitigated. Ethical considerations 
        should always be prioritized when implementing AI solutions in sensitive contexts like war 
        or post-war scenarios.
        
        It's recommended that any implementation be subjected to ongoing ethical review and 
        stakeholder consultation throughout development and deployment phases.
        """)
        
        # Join all sections
        return "\n".join(report_sections)
    
    def process_query(self, query: str):
        """
        Process a user query through the entire RAG + LLM pipeline.
        
        Args:
            query: User's query about a war-related AI use case
            
        Returns:
            A comprehensive report
        """
        print(f"Processing query: '{query}'")
        
        # Step 1: Find relevant use cases
        use_cases = self.find_use_cases(query)
        print(f"Found {len(use_cases)} use cases")
        
        # Step 2: Analyze use cases with LLM
        use_cases_analysis = self.analyze_use_cases(query, use_cases)
        print("Completed use case analysis")
        
        # Step 3-4: Find risks, benefits for each use case
        all_risks_benefits = {}
        for uc_id, use_case in use_cases.items():
            all_risks_benefits[uc_id] = self.find_risks_benefits(use_case)
        print("Retrieved risks and benefits")
        
        # Step 5-6: Find mitigations for each risk
        all_mitigations = {}
        for uc_id, rb in all_risks_benefits.items():
            for risk_idx, risk in enumerate(rb["risks"]):
                all_mitigations[f"{uc_id}_{risk_idx}"] = self.find_mitigations(risk)
        print("Retrieved mitigations")
        
        # Step 7-8: Generate final report
        report = self.generate_report(
            query, 
            use_cases, 
            use_cases_analysis, 
            all_risks_benefits, 
            all_mitigations
        )
        print("Generated report")
        
        return report

def run_example_with_sample_data():
    """Run an example query through the system"""
    uploader = UploaderData()
    #uploader.delete_all_data()

    #uploader.populate_from_paper()
    
    
    # Initialize the analyzer
    analyzer = WarUseCaseAnalyzer()
    
    # Process a sample query
    query = "AI in humanitarian assistance during war"
    report = analyzer.process_query(query)
    
    # Display the report
    with open("report.md", "w") as f:
        f.write(report)
        
    #uploader.delete_all_data()
        
    return report


# When running the notebook directly
if __name__ == "__main__":
    run_example_with_sample_data()